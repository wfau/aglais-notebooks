{
  "paragraphs": [
    {
      "title": "Introduction",
      "text": "%md\n\nThis notebook provides an illustrative workflow that follows the [Kounkel and Covey (2019)](https://ui.adsabs.harvard.edu/abs/2019AJ....158..122K/abstract) kinematic analysis of Gaia DR2 which used unsupervised ML techniques to identify kinematic structures in five-dimensional parameter space. Steps in the analysis illustrated are:\n\n* Initial broad-brush selection from gaia_source from 1.7 billion rows to around 20 million;\n* further filtering of this selection on velocity with respect to the Local Standard of Rest via kinematic transformations expressed in user-defined functions;\n* transformation from Spark to Pandas data frame for input into a third-party implementation of the unsupervised ML clustering algorithm (HDBSCAN \u003d \"hierarchical density-based clustering and noise\").",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eThis notebook provides an illustrative workflow that follows the \u003ca href\u003d\"https://ui.adsabs.harvard.edu/abs/2019AJ....158..122K/abstract\"\u003eKounkel and Covey (2019)\u003c/a\u003e kinematic analysis of Gaia DR2 which used unsupervised ML techniques to identify kinematic structures in five-dimensional parameter space. Steps in the analysis illustrated are:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eInitial broad-brush selection from gaia_source from 1.7 billion rows to around 20 million;\u003c/li\u003e\n  \u003cli\u003efurther filtering of this selection on velocity with respect to the Local Standard of Rest via kinematic transformations expressed in user-defined functions;\u003c/li\u003e\n  \u003cli\u003etransformation from Spark to Pandas data frame for input into a third-party implementation of the unsupervised ML clustering algorithm (HDBSCAN \u003d \u0026ldquo;hierarchical density-based clustering and noise\u0026rdquo;).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_1221237169",
      "id": "20210510-142316_655474866",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    },
    {
      "title": "Raw sample query definition",
      "text": "%pyspark\n\n# initial query on the entire catalogue: predicates come from Kounkel \u0026 Covery (2019) Section 2:\nquery \u003d \u0027select designation, source_id, ra, ra_error, dec, dec_error, parallax, parallax_error, parallax_over_error, pmra, pmra_error, pmdec, pmdec_error, l, b \u0027 + \\\n        \u0027from gaia_source where \u0027 + \\\n        \u0027abs(b) \u003c 30.0 AND parallax \u003e 1.0 and parallax_over_error \u003e 10.0 AND phot_g_mean_flux_over_error \u003e 36.19 AND astrometric_sigma5d_max \u003c 0.3 and \u0027 + \\\n        \u0027visibility_periods_used \u003e 8 and (astrometric_excess_noise \u003c 1 OR (astrometric_excess_noise \u003e 1 AND astrometric_excess_noise_sig \u003c 2))\u0027\n    \n# define a data frame using the query string\ndf \u003d spark.sql(query)\n",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_448789646",
      "id": "20210510-142715_825671906",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    },
    {
      "title": "Function definitions",
      "text": "%pyspark\n\nfrom math import pi, cos, sin\nimport numpy as np\n\n# Generic functions used later\n\ndef convDegRad(args, units\u003d\"degrees\"):\n    \u0027\u0027\u0027\n    NAME\n        convDegRad\n        \n    FUNCTION\n        args in km/sTransforms degrees to radians or returns radians if in radians\n        \n    INPUT\n         args - list of values to convert\n        units - [\u0027degrees\u0027, \u0027radians\u0027] Units of args\n    \n    OUTPUT\n    list of args in radians\n    \u0027\u0027\u0027\n\n    if units \u003d\u003d \u0027degrees\u0027:\n        args \u003d [i*pi/180 for i in args]\n\n    return args\n\ndef convMasKm(args, parallax, units\u003d \u0027mas/yr\u0027):\n    \u0027\u0027\u0027\n    NAME\n        convMasKm\n        \n    FUNCTION\n        Converts data from mas/yr to km/s\n        \n    INPUT\n            args - list of values to convert\n        parallax - parallax of argsmeasurements\n           units - [\u0027mas/yr\u0027, \u0027km/s\u0027] Units of args\n    \n    OUTPUT\n        list of args in km/s\n    \u0027\u0027\u0027\n    \n    if units \u003d\u003d \u0027mas/yr\u0027:\n        k \u003d 4.74057\n        args \u003d [i/parallax * 4.74057 for i in args]\n    elif units !\u003d \u0027km/s\u0027:\n        raise ValueError(\"Input proper motion values in either mas/yr or km/s\")\n        \n    return args\n\ndef matrix_multiplication_arrays(A,B):\n    \u0027\u0027\u0027NAME\n         matrix_multiplication_arrays\n        \n    FUNCTION\n        Matrix multiplication of Matrix A and B if both are either lists or numpy.arrays\n        \n    INPUT\n        A - Matrix A\n        B - Matrix B\n    \n    OUTPUT\n        MAtrix A*B, as an numpy.array\n    \u0027\u0027\u0027\n    \n    if np.shape(A)[1] !\u003d np.shape(B)[0]:\n        return \u0027Invalid matrix shape\u0027\n    else:\n        n,m \u003d np.shape(A)[0], np.shape(B)[1]\n        M \u003d np.zeros((n,m))\n        \n        for i in range(n):\n            for j in range(len(B[0])):\n                E\u003d0\n                for k in range(len(B)):\n#                     print(\u0027A{}{}*B{}{}\u0027.format(i,k,k,j))\n                    E +\u003d A[i][k]*B[k][j]\n                M[i,j] \u003d E\n#                 print(\u0027\\n\u0027)\n        return M\n        \n# Functions to perform the LSR cut\n\ndef create_Matrix_A(ra, dec, coord_units \u003d \u0027degrees\u0027):\n    \u0027\u0027\u0027creates Matrix A, where A \u003d [[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n                                     [sin(ra)*cos(dec),  cos(ra), -sin(ra)*sin(dec)],\n                                     [sin(dec),             0,     cos(dec)]])\u0027\u0027\u0027\n    \n#     if all(v is None for v in {data, ra, dec}):\n#         raise ValueError(\"Expected input either as array or \u0027ra\u0027 and \u0027dec\u0027 values\")\n#     if data is None:\n#         if any(v is None for v in {ra,dec}):\n#             raise ValueError(\"Expected input either as array or \u0027ra\u0027 and \u0027dec\u0027 values\")\n\n    ra,dec \u003d convDegRad([ra,dec], units \u003d coord_units)  # Ensures radians\n        \n    A \u003d np.array([[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n              [sin(ra)*cos(dec), cos(ra), -sin(ra)*sin(dec)],\n              [sin(dec), 0, cos(dec)]])\n    return A\n\ndef create_matrix_C(pmra, pmdec, parallax \u003d None, radial_velocity \u003d 0.0, units \u003d \u0027mas/yr\u0027):\n    \u0027\u0027\u0027creates Matrix C, where C \u003d [radial_velocity, pmra, pmdec]\u0027\u0027\u0027\n    \n    if parallax \u003d\u003d None and units \u003d\u003d \u0027mas/yr\u0027:\n        raise ValueError(\"Parallax value must be supplied if proper motion units are \u0027mas/yr\u0027\")\n\n    pmra,pmdec \u003d convMasKm([pmra, pmdec], parallax \u003d parallax, units \u003d units)  # Ensures proper motions in km/s\n    C \u003d np.array([[radial_velocity, pmra, pmdec]]).T\n    \n    \n    return C\n    \ndef conv_Galactic_LSR(G, magnitude \u003d True):\n    \u0027\u0027\u0027\n    NAME\n        conv_Galactic_LSR\n        \n    FUNCTION\n        Calculates magnitude of LSR velocity give U,V,W velocity.\n        \n    INPUT\n                G - Array of U, W, V velocity in Galactic reference frame\n        Magnitude - [True, False] Return velocity magnitude (True) or LSR components (False)\n    \n    OUTPUT\n        LSR velocity values\n    \n    SEE ALSO\n        v_sun values from Schonrich, R., Binney, J., \u0026 Dehnen, W. 2010 | \n        DOI: 10.1111/j.1365-2966.2010.16253.x\n    \u0027\u0027\u0027\n    v_sun \u003d [11.1, 12.24, 7.25]\n    lsr \u003d np.asarray(G).T + v_sun\n    \n    if magnitude \u003d\u003d True:\n        v_lsr \u003d np.sqrt(np.sum([i**2 for i in lsr]))\n        return v_lsr\n    return lsr\n    \ndef LSR_conv(ra, dec, parallax, pmra, pmdec, coord_units \u003d \u0027degrees\u0027, pm_units\u003d\u0027mas/yr\u0027, radial_velocity \u003d 0.0, magnitude \u003d True):\n    \u0027\u0027\u0027\n    NAME\n        LSR_conv\n        \n    FUNCTION\n        Converts proper motions from ra, dec to LSR velocity\n    \n    REQUIRES:\n              ra - right acension of object\n             dec - declination of object\n        parallax - parallax of object\n            pmra - right ascension component of proper motion\n           pmdec - declination component of proper motion\n        \n    OPTIONAL:\n            coord_units \u003d [defaut \u003d \u0027deg\u0027] units of coordinates (ra, dec). \n                                Accepted values are [\u0027deg\u0027, \u0027rad\u0027]\n               pm_units \u003d [defaut \u003d \u0027mas/yr\u0027] units of proper motions. \n                              Accepted values are: [\u0027mas/yr\u0027, \u0027km/s\u0027]\n        radial_velocity \u003d list of radial velocity (defaults \u003d 0.0)\n                    mag \u003d Return only V_LSR mag (default \u003d True - returns three dimensions of v_lsr [u,v,w])\n    \n    RETURNS\n        lsr velocity [float]\n    \n    SEE ALSO\n         Method from: Johnson, Dean R. H., Soderblom, David R. DOI: 10.1086/114370\n    \u0027\u0027\u0027\n    \n    T \u003d [[-0.05646624, -0.87325802, -0.48397519],\n         [ 0.49253617, -0.44602111,  0.74731071],\n         [-0.86845823, -0.19617746,  0.4552963 ]]\n\n    A \u003d create_Matrix_A(ra,dec, coord_units\u003dcoord_units)   # forms Marix A\n    B \u003d matrix_multiplication_arrays(T, A)  # forms Matrix B\n    \n    C \u003d create_matrix_C(pmra,pmdec,parallax, units \u003d pm_units, radial_velocity \u003d radial_velocity)    # forms Matrix C\n    G \u003d matrix_multiplication_arrays(B,C) # Calculates U, W, V\n\n    v_lsr \u003d conv_Galactic_LSR(G, magnitude \u003d magnitude) # Calculates velocity magnitude in LSR coords\n    \n    return v_lsr\n\n# This function needs to be called by the UDF, all optional parameters are set as required - e.g. show_velocity \u003d False.\n\ndef LSR_cut(ra,dec,parallax,pmra,pmdec, \n            cut \u003d 60, coord_units \u003d \u0027degrees\u0027, \n            pm_units\u003d\u0027mas/yr\u0027, show_velocity \u003d False):\n    \u0027\u0027\u0027\n    NAME\n        LSR_cut\n        \n    FUNCTION\n        Calculates LSR velocity through LSR_conv and returns boolean if satisfies cut condition.\n    \n    REQUIRES:\n              ra - right acension of object\n             dec - declination of object\n        parallax - parallax of object\n            pmra - right ascension component of proper motion\n           pmdec - declination component of proper motion\n    \n    OPTIONAL\n          coord_units \u003d [defaut \u003d \u0027deg\u0027] units of coordinates (ra, dec). \n                             Accepted values are [\u0027deg\u0027, \u0027rad\u0027]\n             pm_units \u003d [defaut \u003d \u0027mas/yr\u0027] units of proper motions. \n                            Accepted values are: [\u0027mas/yr\u0027, \u0027km/s\u0027]\n        show_velocity \u003d [default \u003d False] print lsr velocity? [True/False]\n    \n    RETURNS\n        [Boolean]\n    \u0027\u0027\u0027\n    \n    v \u003d LSR_conv(ra,dec,parallax,pmra,pmdec, coord_units\u003dcoord_units, pm_units\u003dpm_units)\n    if show_velocity \u003d\u003d True:\n        print(v)\n    if v \u003c cut:\n        return 1\n    if v \u003e cut:\n        return 0\n        \n\nfrom pyspark.sql.types import IntegerType\n\n# finally, register the top-level user-defined function for inclusion in queries\nspark.udf.register(\"udf_lsr_cut\", LSR_cut, IntegerType())        \n",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cfunction __main__.LSR_cut(ra, dec, parallax, pmra, pmdec, cut\u003d60, coord_units\u003d\u0027degrees\u0027, pm_units\u003d\u0027mas/yr\u0027, show_velocity\u003dFalse)\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_1990340925",
      "id": "20210510-152257_591411400",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    },
    {
      "title": "Create and cache the primary data set",
      "text": "%pyspark\n\n# apply the velocity cut to the data frame and at this point cache for downstream processing\ndf_lsr_cut \u003d df.select(\"*\").where(\"udf_lsr_cut(ra, dec, parallax, pmra, pmdec) \u003d 1\").cache()\n\n# sanity check\ndf_lsr_cut.show()\n# print (\"Data frame rows: \",df_lsr_cut.count())\n# 23,180,273 EDR3 cf. Kounkel \u0026 Covey (2019) on DR2 ~20,000,000. Cell runs in 12 min 29 sec.",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+-----------------+------------------+-----------+------------------+-----------+------------------+--------------+-------------------+-------------------+-----------+--------------------+------------+------------------+-------------------+\n|         designation|        source_id|                ra|   ra_error|               dec|  dec_error|          parallax|parallax_error|parallax_over_error|               pmra| pmra_error|               pmdec| pmdec_error|                 l|                  b|\n+--------------------+-----------------+------------------+-----------+------------------+-----------+------------------+--------------+-------------------+-------------------+-----------+--------------------+------------+------------------+-------------------+\n|Gaia EDR3 3854757...|38547576296948352|59.692813119350646| 0.10669451|13.558776016867576| 0.07782336|2.4503861362319888|   0.121595174|          20.152002|  3.103350822913168| 0.15850544|  -4.453747814360777|  0.09969241| 177.1037086342729| -29.01182654639396|\n|Gaia EDR3 4339941...|43399411873079424|   58.200732134555|0.049338993| 16.43557230177881|0.040645678| 1.059049877147188|   0.055046383|          19.239227|  6.405404518106619| 0.06464208|  -5.673330968998795|  0.05296004|173.59121304003824|-28.098019453443225|\n|Gaia EDR3 4350173...|43501735174322432| 58.48944580934948|0.013642826|  16.6289222180115|0.009253155|1.3895817555315542|   0.014816899|           93.78358|  6.422551875086374|0.018126765|  -10.98071923815659| 0.012287473| 173.6519699698631|-27.764689603986827|\n|Gaia EDR3 4378303...|43783038352532992| 57.73383382910214| 0.03705743|17.250388393805583|0.022125868|  3.47001609191998|   0.039958447|          86.840614|-12.635540013011582|0.046938185|  -1.000655799444372| 0.028612297| 172.5782520527005|-27.846479760305915|\n|Gaia EDR3 4480317...|44803178983448960| 55.96297467352141|0.052949294|18.162854860001588| 0.04257956|1.0302554170163654|    0.05925382|          17.387156|  2.849798327627478|0.066948816|  -9.682699227725509| 0.050964355| 170.4888878327261|-28.377790255245664|\n|Gaia EDR3 4484262...|44842623963230464| 55.04092109074424|0.013391432|18.088463543928818|0.010171429|3.9573981481353164|   0.015688423|          252.24959|  4.211627862091248|0.019242492| -30.789920710983843|0.0135597065| 169.8215379285506|-29.034164728195023|\n|Gaia EDR3 4525332...|45253325915072000| 62.17194417022319| 0.03713166|15.594686896283253| 0.02547773| 1.024427137028435|   0.042658675|           24.01451|  3.117921750270612|0.054698788|    6.83158601514976| 0.039838966|177.19234657243115|-25.866233862584536|\n|Gaia EDR3 4557307...|45573077640552320|  62.0438457521998| 0.02553682|16.561938310017894|0.018492293| 1.376930483522806|   0.028198801|            48.8294|  3.148786903682981| 0.03166126| -2.9667445872113967| 0.026121315|176.29997314636014| -25.31579585426574|\n|Gaia EDR3 4608799...|46087992679647872|63.583919633656144| 0.07253971| 17.74252938528562|0.045340624| 1.434452709643916|    0.08195099|          17.503786| -4.761041341150352| 0.09580613|-0.02522442341694195|  0.07142158| 176.4028101693267|  -23.4315306469328|\n|Gaia EDR3 4847826...|48478262238829952|63.781882578898625|0.027157329|19.012482851009167|0.017030492| 1.890315471726036|   0.031045951|           60.88767| -8.446094442509384|0.030975861| -13.893366672478123| 0.023390427|175.50476665695496|-22.449621924900715|\n|Gaia EDR3 4924534...|49245343398558720| 65.12787044633635|0.019991059|21.033716041288685|0.011877552| 1.602462193376745|   0.021889817|           73.20583|  9.430093016407143| 0.03114954|  -9.762473814524533| 0.021586927|174.78049929193105|-20.162875069633316|\n|Gaia EDR3 5001283...|50012836874991488|59.597665978199274| 0.01911793|18.897008562879222|0.011848555| 1.352899597502433|   0.021174597|           63.89258|-0.6109252887986107|0.028403413| -6.0552320375031075| 0.015546807| 172.6513184194226|-25.428568295079646|\n|Gaia EDR3 5121666...|51216664668533248| 57.33766743500851|0.026758952|20.424264186954463|0.015874859|1.3168981282647685|   0.027364276|          48.124718| 5.1162616997391375|0.032809947|  -2.573361679848148| 0.019368865| 169.7831360093634|-25.847450303189632|\n|Gaia EDR3 5142038...|51420383557644416|60.332680564734794| 0.08065441| 20.79920176709673| 0.05003165|1.8814894470659318|   0.089519896|          21.017557| -1.957669704304258|0.122010194| -3.1586824549393304|  0.06378926|171.68287439569207|  -23.6064884260041|\n|Gaia EDR3 5142533...|51425331359858816| 59.97291126814437| 0.09613138| 20.72274612455047|  0.0624458|2.2646240635473536|    0.10437978|          21.696003| 2.5857711769417846| 0.11696873|   7.950428283098722|  0.07534906|171.48542137180874| -23.90034930702706|\n|Gaia EDR3 5149673...|51496730896076672|59.505687474866875|0.082634166|20.994531238137736| 0.05648626| 1.221103019191246|    0.09631894|          12.677704|-1.8350815436861174| 0.10487301|  1.1719056507692236| 0.071552046|170.93797226020757|-24.019570634851195|\n|Gaia EDR3 5175851...|51758517742897024| 59.15303198293271|0.022264611|  21.4981418903152|0.013097857|1.8334830137862905|   0.022671286|          80.872475|  8.277491952169195|0.028598974|   6.906497832544304|  0.01631765|170.29416391465503| -23.89503085715928|\n|Gaia EDR3 5218560...|52185609291290368|61.221160325724334|0.014588818|20.966105158643124|0.008900392|2.5258896209190893|   0.017271142|          146.24913|  4.826347797573071|0.017734826| -11.358212026055256| 0.011151196|172.18030367094778|-22.893694914740735|\n|Gaia EDR3 5327952...|53279520281273856|59.535621465485434| 0.12997487|21.958204701488356| 0.08731532|2.2069691902236186|     0.1485051|          14.861234|  9.065229910038033| 0.15951361| -11.535456827102081|  0.10863142|170.21584612816292|-23.318124719639496|\n|Gaia EDR3 5379436...|53794366601948544| 61.10474403242291|0.035847567|23.196708842711736|0.025088873|1.7598200779962196|    0.04333309|           40.61146|-3.8399011762988726| 0.04354105|  -2.884215494091352|  0.03162145| 170.3708997674377| -21.41749117166322|\n+--------------------+-----------------+------------------+-----------+------------------+-----------+------------------+--------------+-------------------+-------------------+-----------+--------------------+------------+------------------+-------------------+\nonly showing top 20 rows\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n\u001b[0;32m/tmp/ipykernel_5947/1063203361.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_lsr_cut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 6\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Data frame rows: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_lsr_cut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# 23,180,273 EDR3 cf. Kounkel \u0026 Covey (2019) on DR2 ~20,000,000. Cell runs in 12 min 29 sec.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value \u003d get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\n\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/usr/lib64/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_928497955",
      "id": "20210510-152604_936587614",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    },
    {
      "title": "Define the 5d kinematic data set ",
      "text": "%pyspark\n\n# create a Pandas data frame object for input into HDBSCAN for the kinematic info columns\nhdbscan_pandas_df \u003d df_lsr_cut.select([\u0027l\u0027, \u0027b\u0027, \u0027parallax\u0027,\u0027pmra\u0027,\u0027pmdec\u0027]).toPandas()\n",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_146892983",
      "id": "20210510-153623_1203862364",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    },
    {
      "title": "Run HDBSCAN clusterer",
      "text": "%pyspark\n\nimport hdbscan\n\ndef clustering_info(clusterer, add_to_data\u003dFalse, df\u003d[], index\u003d-1):\n    \u0027\u0027\u0027\n    REQUIRED\n        clusterer \u003d output clusterer from HDBSCAN.\n        \n    OPTIONAL\n        add_to_data \u003d [boolean] Add results to df or return as arrays.\n        df \u003d [Required if add_to_data \u003d True] DataFrame to add results.\n        index \u003d [Default \u003d -1] Column location to add results.\n        \n    RETURNS\n        *groups \u003d Cluster labels for each point in the dataset given to fit(). \n                   Noisy samples are given the label -1.\n        *prob \u003d The strength with which each sample is a member of its assigned cluster.\n        *persistence \u003d A score of how persistent each cluster is. \n                       A score of 1.0 represents a perfectly stable cluster. \n    \n        if add_to_data \u003d False, returns [groups, prob, persistence] as seperate arrays.\n        if add_to_data \u003d True - returns df(DataFrame), persistence (array) - Must provide df to add.\n        \n        (*From HDBSCAN - in SEE ALSO)\n        \n    SEE ALSO\n        https://hdbscan.readthedocs.io/en/latest/\n    \u0027\u0027\u0027\n    # probabilities and group for each object\n    prob\u003dclusterer.probabilities_\n    groups\u003dclusterer.labels_\n\n    # Info on persistence of groups\n    persistence\u003dclusterer.cluster_persistence_\n    \n    print(\u0027Number of Groups \u003d \u0027, max(groups)+1) \n    if add_to_data \u003d\u003d False:\n        return groups, prob, persistence\n    \n    if add_to_data \u003d\u003d True:\n        df\u003dinsert_to_df(df, \u0027group\u0027, groups, index\u003dindex)\n        df\u003dinsert_to_df(df,\u0027probability\u0027, prob, index\u003dindex)\n        return df, persistence\n    \ndef clustering_prediction(clusterer, points_to_predict, cols, add_to_data\u003dFalse, index\u003d-1):\n    \u0027\u0027\u0027\n    REQUIRED\n        clusterer \u003d output clusterer from HDBSCAN.\n        points_to_predict \u003d DataFrame of objects to predict relationships to clustered data.\n        cols \u003d list of columns used for clustering.\n    \n    OPTIONAL\n        add_to_data \u003d [boolean] Add results to points_to_predict or return as arrays.\n        index \u003d [Default \u003d -1] Column location to add results.\n        \n    RETURNS\n        *group \u003d The predicted labels of the points_to_predict\n        *prob \u003d The soft cluster scores for each of the points_to_predict\n        \n        if add_to_data\u003dFalse, returns [group, prob] as seperate arrays.\n        if add_to_data\u003dTrue - returns df(DataFrame) with group and prob added.\n        \n        (*From HDBSCAN - in SEE ALSO)\n        \n    SEE ALSO\n        https://hdbscan.readthedocs.io/en/latest/\n    \u0027\u0027\u0027\n    \n    groups, prob \u003d hdbscan.approximate_predict(clusterer, points_to_predict[cols])\n    if add_to_data \u003d\u003d False:\n        return groups, prob\n    \n    if add_to_data \u003d\u003d True:\n        points_to_predict\u003dinsert_to_df(points_to_predict, \u0027group\u0027, groups, index\u003dindex)\n        points_to_predict\u003dinsert_to_df(points_to_predict,\u0027probability\u0027, prob, index\u003dindex)\n        return points_to_predict\n        \n     \n        \n# Apply HDBSCAN for full data with prediction ON.\nclusterer \u003d hdbscan.HDBSCAN(min_cluster_size\u003d40, min_samples\u003d25, prediction_data\u003dTrue, allow_single_cluster\u003dFalse, cluster_selection_method\u003d\u0027leaf\u0027, gen_min_span_tree\u003dTrue).fit(hdbscan_pandas_df)",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "io.grpc.StatusRuntimeException: UNAVAILABLE: keepalive watchdog timeout\n\tat io.grpc.Status.asRuntimeException(Status.java:526)\n\tat io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\n\tat io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)\n\tat io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)\n\tat io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)\n\tat io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)\n\tat io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:403)\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_1189235950",
      "id": "20210511-165444_823155595",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    },
    {
      "text": "%pyspark\n",
      "user": "gaiauser",
      "dateUpdated": "2021-12-02 10:10:55.504",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1638439855504_708307323",
      "id": "20210531-142725_734621930",
      "dateCreated": "2021-12-02 10:10:55.504",
      "status": "READY"
    }
  ],
  "name": "5d kinematic clustering",
  "id": "2GN5B2XF4",
  "defaultInterpreterGroup": "spark",
  "version": "0.10.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}