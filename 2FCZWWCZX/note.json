{
  "paragraphs": [
    {
      "text": "%spark.pyspark\n\n# define the data frame source on the given column selection/predicates:\ndf \u003d sqlContext.read.parquet(\n    \"/hadoop/gaia/parquet/gdr2/gaia_source/*.parquet\"\n    ).select(\n    [\"designation\",\"source_id\",\"ra\",\"ra_error\",\"dec\",\"dec_error\",\"parallax\",\"parallax_error\",\"parallax_over_error\",\"pmra\",\"pmra_error\",\"pmdec\",\"pmdec_error\",\"l\",\"b\"]\n    ).where(\n    \"abs(b) \u003c 30.0 AND parallax \u003e 1.0 and parallax_over_error \u003e 10.0 AND phot_g_mean_flux_over_error \u003e 36.19 AND astrometric_sigma5d_max \u003c 0.3 AND visibility_periods_used \u003e 8 AND (astrometric_excess_noise \u003c 1 OR (astrometric_excess_noise \u003e 1 AND astrometric_excess_noise_sig \u003c 2))\"\n    )\n\n# sanity check\n#df.show()\n#print (\"Data frame rows: \",df.count())",
      "user": "admin",
      "dateUpdated": "2020-06-11 15:35:14.582",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1591345460603_-1008042604",
      "id": "20200605-082420_1971299308",
      "dateCreated": "2020-06-05 08:24:20.603",
      "dateStarted": "2020-06-11 15:35:14.605",
      "dateFinished": "2020-06-11 15:35:18.878",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\n# Used for a test / check the partitions\n\n# df \u003d df.limit(500)\ndf.rdd.getNumPartitions()",
      "user": "admin",
      "dateUpdated": "2020-06-11 15:37:45.147",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "5985\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1591346221834_1396477280",
      "id": "20200605-083701_931613094",
      "dateCreated": "2020-06-05 08:37:01.834",
      "dateStarted": "2020-06-11 15:37:45.169",
      "dateFinished": "2020-06-11 15:37:45.386",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### Functions include:\n    - convMasKm_sql()               - Converts mas/yr to km/s.\n    - LSR_conv_sql()                - Converts from ra and dec to LSR units. ref: DOI: 10.1086/114370\n        - create_Matrix_A()            - Creates a matrix known as A.\n            - reshape input()             - Reshapes input into list of lists padded/cut to a standard length.\n            - element_transform()         - Returns a list of spark transformations to create an element of A.\n            - create_matrix_index()       - Dreates a list of names for matrix columns e.g. [A00, A10, A20].\n        - create_matrix_C()            - Creates a matrix known as C.\n            - form_matrix_C()             - Selects the correct colunms for C depending on given units\n        - calculate_LSR_mag()          - Calculates LSR mag given U,V,W values\n        - drop_matrix_from_dataframe() - Drops unneeded Matrix columns from spark DataFrame\n    - LSR_cut_sql()                 - Drops all values which exceed a velocity value in LSR units.\n    \n### Additionally:\n    - pd_to_sql             ***UNUSED***  - Converts a pd.DataFrame to sql.DataFrame with option to add an index\n    - addIndexSQL_dataFrame ***UNUSED***  - Adds an index column to a spark DataFrame\n    - Matrix Mulitplication for different inputs:\n        - matrix_multiplication_dataframe_array\n        - matrix_multiplication_array_dataframe\n        - matrix_multiplication_dataframes",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:07:10.086",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eFunctions include:\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e- convMasKm_sql()               - Converts mas/yr to km/s.\n- LSR_conv_sql()                - Converts from ra and dec to LSR units. ref: DOI: 10.1086/114370\n    - create_Matrix_A()            - Creates a matrix known as A.\n        - reshape input()             - Reshapes input into list of lists padded/cut to a standard length.\n        - element_transform()         - Returns a list of spark transformations to create an element of A.\n        - create_matrix_index()       - Dreates a list of names for matrix columns e.g. [A00, A10, A20].\n    - create_matrix_C()            - Creates a matrix known as C.\n        - form_matrix_C()             - Selects the correct colunms for C depending on given units\n    - calculate_LSR_mag()          - Calculates LSR mag given U,V,W values\n    - drop_matrix_from_dataframe() - Drops unneeded Matrix columns from spark DataFrame\n- LSR_cut_sql()                 - Drops all values which exceed a velocity value in LSR units.\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eAdditionally:\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e- pd_to_sql             ***UNUSED***  - Converts a pd.DataFrame to sql.DataFrame with option to add an index\n- addIndexSQL_dataFrame ***UNUSED***  - Adds an index column to a spark DataFrame\n- Matrix Mulitplication for different inputs:\n    - matrix_multiplication_dataframe_array\n    - matrix_multiplication_array_dataframe\n    - matrix_multiplication_dataframes\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1591345486870_-579807609",
      "id": "20200605-082446_1574773946",
      "dateCreated": "2020-06-05 08:24:46.870",
      "dateStarted": "2020-06-05 16:07:10.054",
      "dateFinished": "2020-06-05 16:07:10.066",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\nfrom pyspark.sql.functions import lit, col, cos, sin\nfrom numpy import pi\nimport numpy as np",
      "user": "admin",
      "dateUpdated": "2020-06-11 15:37:54.153",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1591345598008_-2005936421",
      "id": "20200605-082638_855964145",
      "dateCreated": "2020-06-05 08:26:38.008",
      "dateStarted": "2020-06-11 15:37:54.172",
      "dateFinished": "2020-06-11 15:37:54.197",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n# Matrix multiplication functions\n\ndef matrix_multiplication_dataframe_array(A,B,A_name \u003d \u0027A\u0027, name \u003d \u0027C\u0027, drop_A \u003d True):\n    \u0027\u0027\u0027return A with A*B appended as columns named name--, e.g. C--\n    drop_A \u003d True, only return new columns, e.g. C--. \u0027\u0027\u0027\n    \n    n,m \u003d 3, np.shape(B)[1]\n    M \u003d np.zeros((n,m))\n    \n    for i in range(n):\n        for j in range(len(B[0])):\n            element \u003d [(col(\u0027{}{}{}\u0027.format(A_name,i,k)) * B[k][j]) for k in range(len(B))]\n            if len(element) \u003c 3:\n                element.append(0)\n\n            A \u003d A.withColumn(\u0027{}{}{}\u0027.format(name,i,j), element[0]+element[1]+element[2])\n    if drop_A \u003d\u003d True:\n        res \u003d A.select([i for i in A.columns if name in i])\n        return res\n    else:\n        return A\n    \n\ndef matrix_multiplication_array_dataframe(A, B, B_name \u003d \u0027B\u0027, name \u003d \u0027C\u0027, drop_B \u003d True):\n    \u0027\u0027\u0027return A with A*B appended as columns named name--, e.g. C--\n    drop_A \u003d True, only return new columns, e.g. C--. \u0027\u0027\u0027\n    \n    n,m \u003d np.shape(A)[0], 3\n    M \u003d np.zeros((n,m))\n    \n    for i in range(n):\n        for j in range(3):\n            element \u003d [ A[i][k]*col(\u0027{}{}{}\u0027.format(B_name,k,j)) for k in range(3)]\n            if len(element) \u003c 3:\n                element.append(0)\n\n            B \u003d B.withColumn(\u0027{}{}{}\u0027.format(name,i,j), element[0]+element[1]+element[2])\n    if drop_B \u003d\u003d True:\n        res \u003d B.select([i for i in B.columns if name in i])\n        return res\n    else:\n        return B\n\n    \ndef matrix_multiplication_dataframes(df, A_name \u003d \u0027A\u0027, B_name \u003d \u0027B\u0027, name \u003d \u0027C\u0027, drop_A \u003d True):\n    \u0027\u0027\u0027multipies two matricies in the same dataframe and adds new matrix to end\n    \n    ISSUES: \n        Need to automate the input shapes currently only takes a 3x3 * 3x1.\u0027\u0027\u0027\n    \n    n,m \u003d 3, 1\n    M \u003d np.zeros((n,m))\n    \n    for i in range(n):\n        for j in range(m):\n#             print([ \u0027{}{}{}\u0027.format(A_name,i,k)+\u0027{}{}{}\u0027.format(B_name,k,j) for k in range(3)])\n            element \u003d [ col(\u0027{}{}{}\u0027.format(A_name,i,k))*col(\u0027{}{}{}\u0027.format(B_name,k,j)) for k in range(3)]\n            \n            \n            df \u003d df.withColumn(\u0027{}{}{}\u0027.format(name,i,j), element[0]+element[1]+element[2])\n    if drop_A \u003d\u003d True:\n        res \u003d df.select([i for i in df.columns if name in i])\n        return res\n    return df",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:07:50.167",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1591345624605_-1651034958",
      "id": "20200605-082704_1644883668",
      "dateCreated": "2020-06-05 08:27:04.605",
      "dateStarted": "2020-06-05 16:07:50.186",
      "dateFinished": "2020-06-05 16:07:50.197",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n# Houskeeping functions to smooth the pipeline and reduce memory usage\n\ndef reshape_input(Input, padding \u003d 1, desired_length \u003d 2):\n    \u0027\u0027\u0027reshapes input into list of lists padded/cut to a standard desired length\n    \n    EXAMPLE\n        input \u003d [[cos, cos], [sin], [cos, sin, cos],\n                 [sin, cos], [cos], [sin, sin],\n                   [sin],     [0],    [cos]]\n                   \n        new_input \u003d  reshape_input(input, padding \u003d 1) \n        \n        new_input \u003d [[cos, cos], [sin, 1], [cos, sin],\n                     [sin, cos], [cos, 1], [sin, sin],\n                      [sin, 1],   [0, 1],   [cos, 1]]\n        \u0027\u0027\u0027\n    \n    for i in Input:\n        if len(i) \u003c desired_length:\n            while len(i) \u003c desired_length:\n                i.append(padding)\n        elif len(i)\u003edesired_length: \n            while len(i) \u003e desired_length:\n                i.pop()\n    return Input\n\ndef element_transform(function, col_name, sign \u003d 1, padding \u003d 1, col_units \u003d \u0027degrees\u0027):\n    \u0027\u0027\u0027Returns the spark syntax to select and transform columns from a dataframe\n    \u0027\u0027\u0027\n    \n    if function \u003d\u003d padding:\n        return 1\n    \n    elif type(function) \u003d\u003d int: \n        return lit(function)\n    \n    else:\n        if col_units \u003d\u003d \u0027degrees\u0027:\n            conv\u003dpi/180\n        else:\n            conv \u003d 1\n        return sign*function(col(col_name)*conv)\n    \ndef drop_matrix_from_dataframe(df, name):\n    \u0027\u0027\u0027Drops matrix from the dataframe, assuming the column names\n    use function: \"create_matrix_index\" notation. \u0027\u0027\u0027\n    drop \u003d [i for i in df.columns if name in i]\n    df \u003d df.select([column for column in df.columns if column not in drop])\n    return df\n\ndef create_matrix_index(N,M, matrix_name \u003d \u0027A\u0027):\n    \u0027\u0027\u0027Creates index for matrix column names.\u0027\u0027\u0027\n    indicies\u003d[]\n    for i in range(M):\n        for j in range(N):\n            indicies.append(\u0027{}{}{}\u0027.format(matrix_name,i,j))\n    return indicies",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:07:55.173",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1591345681072_-1378545920",
      "id": "20200605-082801_2100975987",
      "dateCreated": "2020-06-05 08:28:01.073",
      "dateStarted": "2020-06-05 16:07:55.192",
      "dateFinished": "2020-06-05 16:07:55.200",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\n\ndef create_Matrix_A(df, drop_df \u003d True, coord_units \u003d \u0027degrees\u0027):\n    \u0027\u0027\u0027creates Matrix A, where A \u003d [[cos(ra)*cos(dec), -sin(ra), -cos(ra)*sin(dec)],\n                                     [sin(ra)*cos(dec),  cos(ra), -sin(ra)*sin(dec)],\n                                     [sin(dec),             0,     cos(dec)]])\u0027\u0027\u0027\n\n    # creating the filter for df\n    trig_funcs \u003d [[cos, cos], [sin], [cos, sin],\n                       [sin, cos], [cos], [sin, sin],\n                       [sin], [0], [cos]]\n    trig_funcs \u003d  reshape_input(trig_funcs)\n\n    cols \u003d [[\u0027ra\u0027, \u0027dec\u0027], [\u0027ra\u0027], [\u0027ra\u0027, \u0027dec\u0027],\n            [\u0027ra\u0027, \u0027dec\u0027], [\u0027ra\u0027], [\u0027ra\u0027, \u0027dec\u0027],\n            [\u0027dec\u0027], [], [\u0027dec\u0027]]\n    cols \u003d reshape_input(cols)\n\n    signs \u003d [1, -1, -1,\n             1,  1, -1, \n             1,  1,  1]\n\n    matrix_cols\u003d[]\n    for i in range(len(signs)):\n        a \u003d element_transform(trig_funcs[i][0], cols[i][0], sign \u003d signs[i], col_units\u003dcoord_units) * \\\n            element_transform(trig_funcs[i][1], cols[i][1], col_units\u003dcoord_units)\n        matrix_cols.append(a)\n\n    names \u003d create_matrix_index(3,3, \u0027A\u0027)\n    if drop_df \u003d\u003d True:\n        A \u003d df.select([c for c in matrix_cols])\n        for i in range(len(signs)):\n            A \u003d A.withColumnRenamed(A.columns[i], names[i])\n        return A\n    else:\n        for i in range(len(matrix_cols)):\n            df \u003d df.withColumn(names[i], matrix_cols[i])\n        index \u003d len(df.columns) - len(signs)\n        for i in range(len(signs)):\n            df \u003d df.withColumnRenamed(df.columns[index+i], names[i])\n        return df\n\n\ndef form_matrix_C(df, radial_velocity\u003d0, drop_df \u003d True):\n    \u0027\u0027\u0027Selects the correct columns for C depending on given units of columns.\u0027\u0027\u0027\n    \n    if radial_velocity \u003d\u003d 0:\n        df \u003d df.withColumn(\u0027C00\u0027, lit(radial_velocity))\\\n            .withColumnRenamed(\u0027pmra (km/s)\u0027,  \u0027C10\u0027)\\\n            .withColumnRenamed(\u0027pmdec (km/s)\u0027, \u0027C20\u0027)\n    else:\n        df \u003d df.select(col(\u0027radial_velocity\u0027), col(\u0027pmra (km/s)\u0027), col(\u0027pmdec (km/s)\u0027))\\\n            .withColumnRenamed(\u0027radial_velocity\u0027, \u0027C00\u0027)\\\n            .withColumnRenamed(\u0027pmra (km/s)\u0027,     \u0027C10\u0027)\\\n            .withColumnRenamed(\u0027pmdec (km/s)\u0027,    \u0027C20\u0027)\n    if drop_df \u003d\u003d True:      \n        C \u003d df.select(\u0027C00\u0027, \u0027C10\u0027, \u0027C20\u0027)\n        return C\n    return df\n\n\ndef create_matrix_C(df, pm_units \u003d \u0027mas/yr\u0027, drop_df \u003d True):\n    \u0027\u0027\u0027 Calls \"form_Matrix_C\" with the correct input columns.\u0027\u0027\u0027\n    \n    if \u0027pmra (km/s)\u0027 in df.columns and \u0027pmra (km/s)\u0027 in df.columns:\n        C \u003d form_matrix_C(df, drop_df\u003ddrop_df)\n\n    elif pm_units \u003d\u003d \u0027mas/yr\u0027:\n        df \u003d convMasKm_sql(df, \u0027pmra\u0027, \u0027pmdec\u0027)\n        C  \u003d  from_matrix_C(df, drop_df\u003ddrop_df)\n\n    elif pm_units \u003d\u003d \u0027km/s\u0027:\n        df \u003d df.withColumnRenamed(\u0027pmra\u0027, \u0027pmra (km/s)\u0027)\\\n               .withColumnRenamed(\u0027pmdec\u0027, \u0027pmdec (km/s)\u0027)\n        C  \u003d form_matrix_C(df, drop_df\u003ddrop_df)\n        df \u003d df.withColumnRenamed(\u0027pmra (km/s)\u0027, \u0027pmra\u0027)\\\n               .withColumnRenamed(\u0027pmdec (km/s)\u0027, \u0027pmdec\u0027)\n    return C\n\ndef calculate_LSR_mag(df, name \u003d \u0027U\u0027):\n    \u0027\u0027\u0027 Calculates magnitude of LSR velocity give U,V,W velocity.\n    Uses v_sun from Schonrich, R., Binney, J., \u0026 Dehnen, W. 2010 | \n    DOI: 10.1111/j.1365-2966.2010.16253.x\n    \u0027\u0027\u0027\n    \n    v_sun \u003d [11.1, 12.24, 7.25]\n    df \u003d df.withColumn(\u0027v_lsr^2\u0027, (col(\u0027{}00\u0027.format(name))+v_sun[0])**2 + \n                                  (col(\u0027{}10\u0027.format(name))+v_sun[1])**2 + \n                                  (col(\u0027{}20\u0027.format(name))+v_sun[2])**2)\n    df \u003d drop_matrix_from_dataframe(df, \u0027U\u0027)\n    return df",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:08:00.134",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1591345695809_-857443660",
      "id": "20200605-082815_1649276127",
      "dateCreated": "2020-06-05 08:28:15.809",
      "dateStarted": "2020-06-05 16:08:00.151",
      "dateFinished": "2020-06-05 16:08:00.160",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\ndef convMasKm_sql(df, args, add_to_data \u003d True):\n    \u0027\u0027\u0027\n    NAME\n        convMasKm_sql\n        \n    FUNCTION\n        Converts data from mas/yr to km/s\n    \n    REQUIRES:\n        df \u003d sql.DataFrame as an input with column [\u0027parallax\u0027 in mas/yr] and any args provided\n        *args \u003d columns names of df you wish to convert from mas/yr to km/s\n    \n    RETURNS\n    \n        if add_to_data \u003d False - returns first column in *args [km/s] as an sql.DataFrame\n        if add_to_data \u003d True  - returns df with all *args [km/s] added.\n    \u0027\u0027\u0027\n    \n    for i in args:\n        df \u003d df.withColumn(str(i + \u0027 (km/s)\u0027), col(i)/col(\u0027parallax\u0027)*4.74057)\n        \n        if add_to_data \u003d\u003d False:   # Returns first column in args as np.array\n            return df.select(str(args[0] + \u0027 (km/s)\u0027))\n            break\n    \n    return df\n\ndef LSR_conv_sql(df, cut \u003d 60, coord_units \u003d \u0027degrees\u0027):\n    \u0027\u0027\u0027NAME\n        LSR_conv\n        \n    FUNCTION\n        Converts proper motions from ra, dec to LSR velocity\n    \n    REQUIRES:\n        df \u003d dataframe of ra, dec, parallax, pmra, pmdec values respectively\n        \n    OPTIONAL:\n        coord_units \u003d [defaut \u003d \u0027deg\u0027] units of coordinates (ra, dec). \n                      Accepted values are [\u0027deg\u0027, \u0027rad\u0027]\n        pm_units \u003d [defaut \u003d \u0027mas/yr\u0027] units of proper motions. \n                    Accepted values are: [\u0027mas/yr\u0027, \u0027km/s\u0027]\n        radial_velocity \u003d list of radial velocity (defaults \u003d 0.0)\n        mag \u003d Return only V_LSR mag (default \u003d False - returns three dimensions of v_lsr [u,v,w])\n    \n    SEE ALSO\n         Method from: Johnson, Dean R. H., Soderblom, David R. DOI: 10.1086/114370\n    \u0027\u0027\u0027\n    \n   \n    \n    T \u003d [[-0.05646624, -0.87325802, -0.48397519],\n         [ 0.49253617, -0.44602111,  0.74731071],\n         [-0.86845823, -0.19617746,  0.4552963 ]]\n\n    df \u003d create_Matrix_A(df, drop_df\u003dFalse, coord_units\u003dcoord_units)   # forms Marix A\n    df \u003d matrix_multiplication_array_dataframe(T,df, B_name \u003d \u0027A\u0027,\n                                               name \u003d \u0027B\u0027, drop_B \u003d False)  # forms Matrix B\n    \n    df \u003d drop_matrix_from_dataframe(df, \u0027A\u0027)   # drops A from df\n    df \u003d create_matrix_C(df, drop_df\u003dFalse)    # forms Matrix C\n    \n    df \u003d matrix_multiplication_dataframes(df, A_name \u003d \u0027B\u0027,\n                                          B_name \u003d \u0027C\u0027, name \u003d \u0027U\u0027, drop_A \u003d False) # Creates U, W, V\n    df \u003d drop_matrix_from_dataframe(df, \u0027B\u0027)   # drops B from df\n\n    df \u003d df.withColumnRenamed(\u0027C10\u0027, \u0027pmra (km/s)\u0027)\\\n        .withColumnRenamed(\u0027C20\u0027, \u0027pmdec (km/s)\u0027)   # Cleaning up DataFrame Columns\n    df \u003d drop_matrix_from_dataframe(df, \u0027C\u0027)   # drops C from df\n    df \u003d calculate_LSR_mag(df, name \u003d \u0027U\u0027)                 # Adds v_lsr^2 column to df\n    \n    return df\n\n\n\ndef LSR_cut_sql(df, cut, column, calc_lsr \u003d True, drop_lsr \u003d True):\n    \u0027\u0027\u0027\n    NAME\n        LSR_cut_sql\n        \n    FUNCTION\n        Cuts the data according to below a certain value\n    \n    REQUIRES:\n        df \u003d input pd.DataFrame\n        cut \u003d v_max^2 for the LSR velocity\n\n    OPTIONAL\n        calc_lsr \u003d calculate lsr velocity if not present - [True/False]\n        drop_lsr \u003d drop v_lsr from df - [True/False]\n        \n    RETURNS\n        DataFrame contiaining only objects which satisfy the cut value\u0027\u0027\u0027\n\n    if calc_lsr \u003d\u003d True:  df \u003d LSR_conv_sql(df)                   # Calcs the lsr velocity\n    if drop_lsr \u003d\u003d True:  df \u003d df.filter(col(column) \u003c cut).drop(col(column))\n    else: df \u003d df.filter(col(column) \u003c cut)\n    return df",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:08:06.839",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1591345782865_-2012503220",
      "id": "20200605-082942_1383508520",
      "dateCreated": "2020-06-05 08:29:42.865",
      "dateStarted": "2020-06-05 16:08:06.856",
      "dateFinished": "2020-06-05 16:08:06.866",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n\ndf \u003d convMasKm_sql(df, [\u0027pmra\u0027, \u0027pmdec\u0027])      # converts proper motions to km/s.\ndf \u003d LSR_conv_sql(df)\ndf \u003d LSR_cut_sql(df, 3600, \u0027v_lsr^2\u0027, True, False)   # calculates v_lsr**2 and drops objects above the cut (squared)\n\n# Sanity Check\nprint(\"Number of rows \u003d {}\".format(df.count()), \"\\n\")",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:08:16.789",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(\u0027Number of rows \u003d 18695675\u0027, \u0027\\n\u0027)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1591345879097_616307639",
      "id": "20200605-083119_988308482",
      "dateCreated": "2020-06-05 08:31:19.097",
      "dateStarted": "2020-06-05 16:08:16.802",
      "dateFinished": "2020-06-05 16:13:32.424",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.pyspark\n",
      "user": "gaiauser",
      "dateUpdated": "2020-06-05 16:05:31.855",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1591373131853_1284137937",
      "id": "20200605-160531_50624032",
      "dateCreated": "2020-06-05 16:05:31.853",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Kounkel \u0026 Covey Spark (Vectorized)",
  "id": "2FCZWWCZX",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "python:shared_process": [],
    "sh:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}