{
  "metadata": {
    "name": "7. Good astrometric solutions via ML Random Forrest classifier",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003c!--\n\n    Gaia Data Processing and Analysis Consortium (DPAC) \n    Co-ordination Unit 9 Work Package 930\n    \n    (c) 2005-2025 Gaia DPAC\n    \n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see \u003chttps://www.gnu.org/licenses/\u003e.\n    --\u003e\n\n# Using ML to define an astrometrically clean sample of stars\n\nFollows the Gaia EDR3 performance verification \"The Gaia Catalogue of Nearby Stars\" (Smart et al. 2021) in classifying astrometric solutions as good or bad via supervised ML. Employs a Random Forrest classifier plus appropriately defined training sets - see https://arxiv.org/abs/2012.02061 for further details. The work flow implemented here follows closely that described in Section 2, \"GCNS Generation\" (GCNS \u003d Gaia Catalogue of Nearby Stars) and is designed to clean up a 100pc (\u003d nearby) sample.\n\n   "
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nimport gaiadmpsetup\n\n# this is the set of astrometric features to be used. In reality several iterations of this workflow might be required with an expanded set, and some figure-of-merit,\n# e.g. Gini index, would be used to select those most important to the RF classification - cf. Table A.1 in the GCNS paper.\nastrometric_features \u003d [\n    \u0027parallax_error\u0027, \n    \u0027parallax_over_error\u0027,\n    \u0027astrometric_sigma5d_max\u0027,\n    \u0027pmra_error\u0027,\n    \u0027pmdec_error\u0027,\n    \u0027astrometric_excess_noise\u0027,\n    \u0027ipd_gof_harmonic_amplitude\u0027,\n    \u0027ruwe\u0027, \n    \u0027visibility_periods_used\u0027,\n    \u0027pmdec\u0027,\n    \u0027pmra\u0027,\n    \u0027ipd_frac_odd_win\u0027,\n    \u0027ipd_frac_multi_peak\u0027,\n    \u0027astrometric_gof_al\u0027,\n    \u0027parallax_pmdec_corr\u0027,\n    \u0027astrometric_excess_noise_sig\u0027\n]\n# ... the last two are included to cross check against the Gini index results presented in the paper.\n\n# quick mode: set an additional predicate filter on random_index here to limit to 10% (or 1%: change 10 to 100) sampling etc:\nquick_filter \u003d \u0027\u0027# AND MOD(random_index, 10) \u003d 0\u0027\n# ... to switch this off, simply specify an empty string. But to avoid overloading matplotlib when visualising results, keep this one:\nquick_plot_filter \u003d \u0027 AND MOD(random_index, 25) \u003d 0\u0027\n\n# reformat the above attribute list into an SQL comma-separated select string\nfeatures_select_string \u003d (\u0027%s, \u0027*(len(astrometric_features) - 1) + \u0027%s \u0027)%tuple(astrometric_features)\n#print (features_select_string)\n\n# Confirmed by Luis Sarro, personal communication: actually we train on ABS(parallax_over_error), see e.g. GCNS paper Figure A.5\nfeatures_select_string \u003d features_select_string.replace(\u0027parallax_over_error\u0027,\u0027ABS(parallax_over_error) AS parallax_over_error\u0027)\n\n# photometric consistency predicate - e.g. Evans et al. (2018), Babusiaux et al. (2018) for DR2:\n#photometric_consistency_filter \u003d \u0027 AND phot_bp_rp_excess_factor BETWEEN 1.0 + (0.03 * POW(bp_rp, 2.0)) AND 1.3 + (0.06 * POW(bp_rp, 2.0))\u0027\n# Riello et al. (2020) for EDR3: fgbp_grp defined by Equation 6 and coefficients in Table 2; sig_cstarg defined by Equation 18:\nphotometric_consistency_indicators \u003d \\\n    \u00271.15436 + 0.033772*bp_rp + 0.032277*bp_rp*bp_rp AS fgbp_grp_0p5, \u0027 + \\\n    \u00271.162004 + 0.011464*bp_rp + 0.049255*bp_rp*bp_rp -0.005879*bp_rp*bp_rp*bp_rp AS fgbp_grp_0p5_4p0, \u0027 + \\\n    \u00271.057572 + 0.0140537*bp_rp AS fgbp_grp_4p0, \u0027 + \\\n    \u00270.0059898 + 8.817481e-12*POW(phot_g_mean_mag, 7.618399) AS sig_cstarg, \u0027\nphotometric_consistency_filter \u003d \u0027 AND (\u0027 + \\\n    \u0027(bp_rp \u003c 0.5 AND ABS(phot_bp_rp_excess_factor - fgbp_grp_0p5) \u003c 2.0 * sig_cstarg) OR \u0027 + \\\n    \u0027(bp_rp BETWEEN 0.5 AND 4.0 AND ABS(phot_bp_rp_excess_factor - fgbp_grp_0p5_4p0) \u003c 2.0 * sig_cstarg) OR \u0027 + \\\n    \u0027(bp_rp \u003e\u003d 4.0 AND ABS(phot_bp_rp_excess_factor - fgbp_grp_4p0) \u003c 2.0 * sig_cstarg))\u0027\n# N.B. this \"ultra-clean\" 2-sigma selection loses very faint red objects owing to the GBP photometry issue discussed in Riello et al. (2020), Section 8.1\n# and is done here for simplicity. The GCNS proper uses external (infrared) photometry from 2MASS to define the good training sample.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# clear any previously cached data in the context (cells may be executed in any order, and out-dated by changes from here onwards)\nsqlContext.clearCache()\n\n# a conservative selection of everything that COULD be within 100pc, including things with measured \n# distances putting them outside the 100pc horizon when their true distances are within, and also including \n# loads of spurious chaff with the wheat of course, plus bad things with significant, unphysical parallaxes:\nraw_sources_df \u003d spark.sql(\u0027SELECT source_id, random_index, phot_g_mean_mag, phot_bp_rp_excess_factor, bp_rp, g_rp, parallax, ra, dec, b, \u0027 + photometric_consistency_indicators + features_select_string + \u0027 FROM gaiadr3.gaia_source WHERE ABS(parallax) \u003e 8.0\u0027)\n\n# cache it for speedy access below (all subsequent samples are derived from this):\nraw_sources_cached \u003d raw_sources_df.cache()\n# ... some good advice concerning caching in Spark here: https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34\n\n# register as SQL-queryable\nraw_sources_cached.createOrReplaceTempView(\u0027raw_sources\u0027)\n\nraw_sources_cached.count()\n# EDR3: 1,724,028 sources in 10min 21sec\n# (cf. GCNS: 1,211,740 sources with varpi \u003e 8mas plus 512,288 sources with varpi \u003c -8 \u003d 1,724,028 in total) "
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# plot an observational Hertzsprung-Russell diagram (aka colour / absolute magnitude diagram) for the unclassified sample to show the problem,\n# include the photometric consistency filter to show the problem is astrometric in addition to photometric\nunclassified_camd_df \u003d spark.sql(\u0027SELECT phot_g_mean_mag + 5.0*LOG10(parallax/100.0) AS m_g, g_rp FROM raw_sources WHERE parallax \u003e +8.0\u0027 + quick_plot_filter)# + photometric_consistency_filter)\n\nimport matplotlib.pyplot as plot\nplot.figure(0, figsize \u003d (9.0, 9.0))\nx \u003d list(unclassified_camd_df.select(\u0027g_rp\u0027).toPandas()[\u0027g_rp\u0027])\ny \u003d list(unclassified_camd_df.select(\u0027m_g\u0027).toPandas()[\u0027m_g\u0027])\nplot.scatter(x, y, marker \u003d \u0027.\u0027, s \u003d 1)\nplot.ylim(21.0, -3.0)\nplot.ylabel(\u0027Stellar brightness (absolute G magnitude) --\u003e\u0027, fontsize \u003d 16)\nplot.xlabel(\u0027\u003c-- Stellar temperature (G - RP magnitude)\u0027, fontsize \u003d 16)\nplot.show()\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cbr\u003eThe problem: while we see astrophysically interesting locii in the colour / absolute-magnitude diagram in the previous cell, the lower right (cool, low temperature) regime is dominated by systematic errors (not random uncertainties - the data should be equally precise in all parts of this data space) that create contamination in the raw sample. We wish to clean the sample to obtain high reliability\n\n* without compromising completeness;\n* utilising astrometric quality features in the raw catalogue for a volume-complete sample;\n* and efficiently; \n\ni.e. without endless iterations of manual, subjective, axis-parallel and arbitrary cuts on available catalogue attributes. A neat solution to this is to use supervised ML. In the Gaia EDR3 performance verification paper \"Gaia Catalogue of Nearby Stars\" (Smart, Sarro, Rybicki, et al. 2020) we use a Random Forest of decision trees on selected features having first defined a training set based on the data itself. \n\nAn 8 mas training set of \"good\" examples is \"cleaned\" of highly probable spurious sources using \u003ci\u003eindependent\u003c/i\u003e photometric criteria, i.e. we require consistency of optical colours. The \"bad\" examples are selected having (unphysical) parallax \u003c -8 mas, i.e. using parallax measurements that are formally highly significant, yet obviously spurious. Under the assumption of normally distributed uncertainties on the parallax measurements, this bad sample should be representative of the corresponding spurious measurements having parallax \u003e 8 mas that contaminate the parallax-selected sample and, in particular, create the contamination illustrated in the plot above.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# good training data: first define rough positional cuts to exclude crowded regions at low Galactic latitude, and inside the Large and Small Magellanic Clouds (Luri et al. 2020):\nlow_galactic_latitude_filter \u003d \u0027 AND ABS(b) \u003e 25.0\u0027\nsmc_filter \u003d \u0027 AND (dec \u003c -80.0 OR dec \u003e -65.0 OR (ra \u003c 350.0 AND ra \u003e +40.0))\u0027\nlmc_filter \u003d \u0027 AND (dec \u003c -80.0 OR dec \u003e -55.0 OR ra \u003c 40.0 OR ra \u003e 120.0)\u0027\nall_good_training_df \u003d spark.sql(\u0027SELECT 1 AS label, \u0027 + features_select_string + \u0027 FROM raw_sources WHERE parallax \u003e + 8.0 AND ABS(b) \u003e 25.0\u0027 + photometric_consistency_filter + quick_filter + low_galactic_latitude_filter + smc_filter + lmc_filter)\ngood_training_rows \u003d all_good_training_df.count()\nprint(\u0027Good training data size: %d rows\u0027%(good_training_rows))\n\n# bad training data: negative parallaxes: N.B. make a selection exactly the same size as the good training set based on size of smaller (good) data set and count of all available bads\nmaximal_bad_ast_count \u003d spark.sql(\u0027SELECT source_id FROM raw_sources WHERE parallax \u003c -8.0\u0027).count()\nfilter_factor \u003d int(maximal_bad_ast_count / good_training_rows)\nall_bad_training_df \u003d spark.sql(\u0027SELECT 0 AS label, \u0027 + features_select_string + \u0027 FROM raw_sources WHERE  parallax \u003c -8.0 AND MOD(random_index, %d) \u003d 0\u0027%(filter_factor) + \u0027 ORDER BY random_index LIMIT %d\u0027%(good_training_rows))\nall_bad_training_data_count \u003d all_bad_training_df.count()\nprint (\u0027Bad  training data size: %d rows\u0027%(all_bad_training_data_count))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# define training (67%) and test (33%) sample splits (seeded randomness for repeatability)\ngood_67pc, good_33pc \u003d all_good_training_df.randomSplit([0.67, 0.33], 42)\nbad_67pc, bad_33pc \u003d all_bad_training_df.randomSplit([0.67, 0.33], 42)\n\n# transform to labelled feature vectors (0.0 \u003d bad, 1.0 \u003d good, as conveniently already defined in previous projections above)\n\n# Annotate and transform appropriate to the input required by the classifier\u0027s API.\n# Need a dataframe with labels and features: use vector assembler. \nfrom pyspark.ml.feature import VectorAssembler\nignore \u003d [\u0027label\u0027,]\nassembler \u003d VectorAssembler(inputCols\u003d[x for x in good_67pc.columns if x not in ignore], outputCol\u003d\u0027features\u0027)\n\n# training sets\ngood_training_df \u003d assembler.transform(good_67pc).drop(*astrometric_features)\nbad_training_df \u003d assembler.transform(bad_67pc).drop(*astrometric_features)\n# ... N.B. the original individual feature columns are dropped to save memory (since they are duplicated into the resulting feature vector).\n\n# testing sets\ngood_testing_df \u003d assembler.transform(good_33pc).drop(*astrometric_features)\nbad_testing_df \u003d assembler.transform(bad_33pc).drop(*astrometric_features)\n\n# concatenate the training set into a single dataframe\ntraining_df \u003d good_training_df.union(bad_training_df)\n#training_df.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# This cell does the business, given the data and training sets. Follows the example Python code at \n# https://spark.apache.org/docs/2.4.7/api/python/pyspark.ml.html#pyspark.ml.classification.RandomForestClassifier\n\nfrom pyspark.ml.classification import RandomForestClassifier\n\n# instantiate a trained RF classifier, seeded for repeatability at this stage:\nrf \u003d RandomForestClassifier(featureSubsetStrategy \u003d \u0027sqrt\u0027, featuresCol \u003d \u0027features\u0027, labelCol \u003d \u0027label\u0027, numTrees \u003d 500, impurity \u003d \u0027gini\u0027, seed\u003d42)\nmodel \u003d rf.fit(training_df)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# in case of any problems in the previous cell, check the features for nulls (there should be none, but if an exception \"Consider removing nulls ...\" is thrown):\n#for feature in astrometric_features: print (spark.sql(\u0027SELECT COUNT(*) AS \u0027 + feature + \u0027_nulls FROM raw_sources WHERE \u0027 + feature + \u0027 IS NULL\u0027).show())"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# classify based on the above trained model\ngood_test_results \u003d model.transform(good_testing_df)\nbad_test_results \u003d model.transform(bad_testing_df)\n\n#good_test_results.show()\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# test results numerical output\n\n# count up\nfrom collections import Counter\npositives \u003d Counter(list(good_test_results.select(\u0027prediction\u0027).toPandas()[\u0027prediction\u0027]))\nnegatives \u003d Counter(list(bad_test_results.select(\u0027prediction\u0027).toPandas()[\u0027prediction\u0027]))\n\n# Confusion matrix (after GCNS paper, Table 1):\ntrue_positives \u003d positives[1.0]\nfalse_positives \u003d positives[0.0]\ntrue_negatives \u003d negatives[0.0]\nfalse_negatives \u003d negatives[1.0]\nprint(\u0027   |%7d%7d\u0027%(1,2))\nprint(\u0027------------------------------\u0027)\nprint(\u0027 1 |%7d%7d\u0027%(true_positives, false_positives))\nprint(\u0027 2 |%7d%7d\u0027%(false_negatives, true_negatives))\nprint()\n\n# Misclassification fraction: cf. GCNS paper which quotes 0.1%\nnum_misclassified \u003d false_positives + false_negatives\ntotal_num_in_test \u003d true_positives + true_negatives + num_misclassified\nmisclassified_pc \u003d 100.0 * float(num_misclassified) / float(total_num_in_test)\nprint(\u0027Misclassifications for the test set: %.2f %%\u0027%(misclassified_pc))\n\n#  10% EDR3 sample, 100 trees: 0.44% misclassifications\n# 100%              500      : 0.38% (in 15min 57sec)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nimport numpy\n\n# examine relative importance of features wrt Appendix A.1 of the GCNS paper\nfeature_relative_importance \u003d model.featureImportances.toArray()\nsort_order \u003d numpy.argsort(feature_relative_importance)\nfor idx in range(len(astrometric_features) - 1, 0, -1): \n    print(\u0027%30s  :  %f\u0027%(astrometric_features[sort_order[idx]], feature_relative_importance[sort_order[idx]]))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# cleaned up CAMD (observational HRD) employing the classifications\n\n# get the complete unclassified sample:\nunclassified_sample_df \u003d spark.sql(\u0027SELECT * FROM raw_sources WHERE parallax \u003e +8.0\u0027 + quick_filter)\n\n# required features subset for the classification model\nassembler \u003d VectorAssembler(inputCols\u003d[x for x in unclassified_sample_df.columns if x in astrometric_features], outputCol\u003d\u0027features\u0027)\ndf_to_classify \u003d assembler.transform(unclassified_sample_df)\nall_classifications \u003d model.transform(df_to_classify)\n#all_classifications.show()\n\n# the above are rather expensive operationa so cache the results for all later plotting cells:\nall_classifications_cached \u003d all_classifications.cache()\n\n# register as SQL-queryable:\nall_classifications_cached.createOrReplaceTempView(\u0027classified_sources\u0027)\n\n# select on binary classification for a quick check:\ngood_sources_df \u003d spark.sql(\u0027SELECT phot_g_mean_mag + 5.0*LOG10(parallax/100.0) AS m_g, g_rp, ra, dec FROM classified_sources WHERE prediction\u003d1.0\u0027 + quick_plot_filter)\nbad_sources_df \u003d  spark.sql(\u0027SELECT phot_g_mean_mag + 5.0*LOG10(parallax/100.0) AS m_g, g_rp, ra, dec FROM classified_sources WHERE prediction\u003d0.0\u0027 + quick_plot_filter)\n\nimport matplotlib.pyplot as plot\nplot.figure(1, figsize \u003d (9.0, 9.0))\nx \u003d list(bad_sources_df.select(\u0027g_rp\u0027).toPandas()[\u0027g_rp\u0027])\ny \u003d list(bad_sources_df.select(\u0027m_g\u0027).toPandas()[\u0027m_g\u0027])\nplot.scatter(x, y, marker \u003d \u0027.\u0027, s \u003d 1, c \u003d \u0027orange\u0027)\nx \u003d list(good_sources_df.select(\u0027g_rp\u0027).toPandas()[\u0027g_rp\u0027])\ny \u003d list(good_sources_df.select(\u0027m_g\u0027).toPandas()[\u0027m_g\u0027])\nplot.scatter(x, y, marker \u003d \u0027.\u0027, s \u003d 1)\nplot.ylim(21.0, -3.0)\nplot.ylabel(\u0027Stellar brightness (absolute G magnitude) --\u003e\u0027, fontsize \u003d 16)\nplot.xlabel(\u0027\u003c-- Stellar temperature (G - RP magnitude)\u0027, fontsize \u003d 16)\nplot.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# histogram of the classification probabilities: cf. GCNS paper Figure 3\n\nimport matplotlib.pyplot as plot\nplot.figure(1, figsize \u003d (9.7, 6.0))\nplot.yscale(\u0027log\u0027)\nx \u003d list(all_classifications_cached.select(\u0027probability\u0027).toPandas()[\u0027probability\u0027])\n# the probability column values are actually rich objects (DenseVector) containing p and 1-p for our two classes\n# so pick one to plot (without the following line, both probabilities are counted up resulting in a symmetrical plot!)\nx \u003d [i.values[1] for i in x]\nplot.hist(x, bins\u003d25, color\u003d\u0027black\u0027)\nplot.xlabel(\u0027Random Forest Probability\u0027)\nplot.ylabel(\u0027N\u0027)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# cf. GCNS paper Figure 1 panels, sky distribution of good/bad sources:\n\nimport math\n\nplot.figure(2, figsize \u003d (16.18, 10.0))\nplot.subplot(111, projection\u003d\u0027aitoff\u0027)\nplot.grid(True)\nx \u003d list((good_sources_df.select(\u0027ra\u0027).toPandas()[\u0027ra\u0027] - 180.0) * math.pi / 180.0)\ny \u003d list(good_sources_df.select(\u0027dec\u0027).toPandas()[\u0027dec\u0027] * math.pi / 180.0)\nplot.title(\u0027Good sources\u0027)\nplot.scatter(x, y, marker \u003d \u0027.\u0027, s \u003d 1)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nplot.figure(3, figsize \u003d (16.18, 10.0))\nplot.subplot(111, projection\u003d\u0027aitoff\u0027)\nplot.grid(True)\nx \u003d list((bad_sources_df.select(\u0027ra\u0027).toPandas()[\u0027ra\u0027] - 180.0) * math.pi / 180.0)\ny \u003d list(bad_sources_df.select(\u0027dec\u0027).toPandas()[\u0027dec\u0027] * math.pi / 180.0)\nplot.title(\u0027Bad sources\u0027)\nplot.scatter(x, y, marker \u003d \u0027.\u0027, s \u003d 1)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# flush the cache to free up memory for other jobs\nsqlContext.clearCache()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "* [Gaia Early Data Release 3: The Gaia Catalogue of Nearby Stars (R.Smart et al. 2021)](https://www.aanda.org/articles/aa/full_html/2021/05/aa39498-20/aa39498-20.html \"Smart et al., A\u0026A, 649 (2021) A6\")\n* [Apache Spark ML API](https://spark.apache.org/docs/2.4.7/ml-statistics.html \"Spark 2.4.7 ML API\")\n* [A classifier for spurious astrometric solutions in Gaia EDR3 (J.Rybizki et al. 2021)](https://arxiv.org/abs/2101.11641 \"astro-ph/2101.11641\")\n* [Python matplotlib plotting library](https://matplotlib.org)\n"
    }
  ]
}